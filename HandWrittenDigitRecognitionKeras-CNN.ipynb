{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirban/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32,(3,3), activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2,2)))\n",
    "model.add(layers.Conv2D(64,(3,3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(10,activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28, 28 , 1))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 , 28 , 1))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 54s 895us/step - loss: 0.1762 - acc: 0.9454\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 53s 881us/step - loss: 0.0476 - acc: 0.9851\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 53s 881us/step - loss: 0.0336 - acc: 0.9895\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 53s 882us/step - loss: 0.0257 - acc: 0.9925\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 53s 890us/step - loss: 0.0197 - acc: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f45d08aa438>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 308us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9918\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.1294337e-08 1.2618837e-08 9.9999702e-01 4.3958988e-07 2.5882491e-12\n",
      "  7.6082988e-13 6.9501391e-11 1.9908526e-08 2.5026936e-06 9.5741340e-14]]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f45b6714358>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45ce7c6550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#temp_img=image.load_img(\"/home/anirban/mnist/train-images/\"+\"4\"+\".jpg\",grayscale=True,target_size=(28,28)) \n",
    "temp_img=image.load_img(\"/home/anirban/Downloads/digit2.png\",grayscale=True,target_size=(28,28)) \n",
    "\n",
    "\n",
    "temp_img=image.img_to_array(temp_img)\n",
    "train_img=temp_img\n",
    "#converting train images to array and applying mean subtraction processing\n",
    "train_img=np.array(train_img)\n",
    "train_img = train_img.reshape((1, 28 , 28 , 1)) \n",
    "train_img = train_img.astype('float32') / 255\n",
    "#train_img=preprocess_input(train_img) print(train_img.shape) \n",
    "lab = model.predict(train_img) \n",
    "print(lab) \n",
    "print(np.argmax(lab))\n",
    "\n",
    "\n",
    "img = image.load_img(\"/home/anirban/Downloads/digit2.png\", target_size=(28, 28))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
