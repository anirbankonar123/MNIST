{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anirban/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512, activation='relu', input_shape=(28 * 28,)))\n",
    "network.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop',\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "test_images = test_images.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 88us/step - loss: 0.2588 - acc: 0.9246\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.1047 - acc: 0.9697\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0699 - acc: 0.9788\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0503 - acc: 0.9849\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 86us/step - loss: 0.0375 - acc: 0.9885\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa4bd91fd68>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 62us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.9774\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9509510e-14 1.8769444e-07 9.7968662e-01 2.0312311e-02 7.2013982e-28\n",
      "  7.8908741e-11 1.3608009e-19 1.1133176e-11 7.9575284e-07 1.6768327e-16]]\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa47bc613c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa47bcabbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing import image \n",
    "from keras.applications.vgg16 import preprocess_input \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#temp_img=image.load_img(\"/home/anirban/mnist/train-images/\"+\"4\"+\".jpg\",grayscale=True,target_size=(28,28)) \n",
    "temp_img=image.load_img(\"/home/anirban/Downloads/digit2.png\",grayscale=True,target_size=(28,28)) \n",
    "\n",
    "\n",
    "temp_img=image.img_to_array(temp_img)\n",
    "train_img=temp_img\n",
    "#converting train images to array and applying mean subtraction processing\n",
    "train_img=np.array(train_img)\n",
    "train_img = train_img.reshape((1, 28 * 28)) \n",
    "train_img = train_img.astype('float32') / 255\n",
    "#train_img=preprocess_input(train_img) print(train_img.shape) \n",
    "lab = network.predict(train_img) \n",
    "print(lab) \n",
    "print(np.argmax(lab))\n",
    "\n",
    "\n",
    "img = image.load_img(\"/home/anirban/Downloads/digit2.png\", target_size=(28, 28))\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
